{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading data and removing no Sales items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476711, 47)\n",
      "476711\n"
     ]
    }
   ],
   "source": [
    "dirpath = '/Users/parulgaba/Desktop/Capstone-Ethos/ConfidentialData/csvdata/'\n",
    "data_path = '/Users/parulgaba/Desktop/Capstone-Ethos/ethos-retail-model/data/'\n",
    "filename = data_path + 'regression_data/' + 'aggregated_summary_store_type_12_weeks.csv'\n",
    "\n",
    "#filename = 'D:\\\\Backup\\\\ISB CBA\\\\Capstone\\\\summary data\\\\aggregated_summary_store_type_12_weeks.csv'\n",
    "\n",
    "chunksize = 10 ** 5\n",
    "rows=0\n",
    "summary_df = pd.DataFrame()\n",
    "for chunk in pd.read_csv(filename, chunksize=chunksize):\n",
    "    summary_df=pd.concat([summary_df,chunk])\n",
    "    rows+=chunk.shape[0]\n",
    "    \n",
    "summary_df.fillna(0)\n",
    "print(summary_df.shape)\n",
    "print (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique items removed with no sales at all for all 3 three years : 0\n"
     ]
    }
   ],
   "source": [
    "#removing items with no sales in the 3 year period\n",
    "items_no_sales = summary_df.groupby(['item_no']).agg({'sales_quantity':'sum'}).reset_index()\n",
    "unique_item_no_sales = items_no_sales[items_no_sales['sales_quantity'] == 0]['item_no'].unique()\n",
    "summary_df = summary_df[~summary_df['item_no'].isin(unique_item_no_sales)]\n",
    "print(\"Unique items removed with no sales at all for all 3 three years : \" + str(len(unique_item_no_sales)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df['stock_prevailing_mrp'] = summary_df['stock_prevailing_mrp'].div(10000)\n",
    "summary_df['billing'] = summary_df['billing'].div(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438196, 47)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df['item_no']=summary_df['item_no'].astype(str)\n",
    "summary_df['period']=summary_df['period'].astype(int)\n",
    "summary_df['case_shape']=summary_df['case_shape'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###      2a. Performing Item Pareto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combine all SKUs of a specific brand that cummulatively account for ~5% or less by Sales billings into a new SKU called \"Others\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2(a)(i) Code for item pareto\n",
    "\n",
    "pareto =0.05\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#warnings.filterwarnings(action='once')\n",
    "\n",
    "# Create a new df with Other items\n",
    "\n",
    "summary_item_pareto_final = pd.DataFrame()\n",
    "lst = []\n",
    "item_mapping_list = []\n",
    "\n",
    "item_cols = ['case_size_range', 'gender','movement', 'material', 'dial_color', 'strap_type', 'strap_color','precious_stone', 'glass', 'case_shape', 'watch_type']\n",
    "brands = summary_df['brand'].unique()\n",
    "for brand in brands:\n",
    "    items_combined_df = pd.DataFrame()\n",
    "\n",
    "    summary_by_brand_df = summary_df[summary_df['brand'] == brand]\n",
    "    item_series = summary_by_brand_df.fillna(0).groupby('item_no').agg({'billing':'sum'}).sort_values('billing',ascending=False)\n",
    "    items_combined_df = pd.concat([items_combined_df, item_series])\n",
    "    \n",
    "    mask=items_combined_df.cumsum()/items_combined_df.sum()>(1-pareto)\n",
    "    mask=mask.iloc[:,0]\n",
    "    \n",
    "    levels=len(summary_by_brand_df['item_no'].unique())\n",
    "    \n",
    "    if levels > 100:\n",
    "        summary_by_brand_df['brand'] = np.where(summary_by_brand_df['item_no'].isin(item_series[mask].index),'Others',summary_by_brand_df['brand'])         \n",
    "        summary_by_brand_df['item_no'] = np.where(summary_by_brand_df['item_no'].isin(item_series[mask].index),'Others',summary_by_brand_df['item_no'])\n",
    "        item_mapping_list = item_mapping_list + item_series[mask].index.to_list()\n",
    "        for col in item_cols:\n",
    "            if summary_df[col].mode()[0] == 'NaN':\n",
    "                print(brand)\n",
    "                print (col)\n",
    "                print(summary_df[col].mode()[0])\n",
    "            summary_by_brand_df[col] = np.where(summary_by_brand_df['item_no'].isin(item_series[mask].index),summary_df[col].mode()[0],summary_by_brand_df[col])\n",
    "    \n",
    "    new_levels=len(summary_by_brand_df['item_no'].unique())\n",
    "    \n",
    "    freq=summary_by_brand_df['item_no'].value_counts()/summary_by_brand_df['item_no'].value_counts().sum()*100\n",
    "    freq=freq.round(2)\n",
    "    \n",
    "    sale_qty=summary_by_brand_df.groupby(['item_no']).agg({'sales_quantity':'sum'}).sort_values('sales_quantity',ascending=False)\n",
    "    sale_qty=sale_qty/sale_qty.sum()*100\n",
    "    sale_qty=sale_qty.round(2)\n",
    "    \n",
    "    try:\n",
    "        Other_Sales_Qty=sale_qty['sales_quantity']['Others']\n",
    "    except:\n",
    "        Other_Sales_Qty=0\n",
    "    bill=summary_by_brand_df.groupby(['item_no']).agg({'billing':'sum'}).sort_values('billing',ascending=False)\n",
    "    bill=bill/bill.sum()*100\n",
    "    bill=bill.round(2)\n",
    "    try:\n",
    "        Other_bill=bill['billing']['Others']\n",
    "    except:\n",
    "        Other_bill=0\n",
    "        \n",
    "    lst.append([brand, levels, new_levels,Other_bill,Other_Sales_Qty])\n",
    "    \n",
    "    cols=['Brand', 'Orig SKU count', 'New SKU count', 'Other%(Billing)', 'Other%(Sales Qty)']\n",
    "    item_pareto_summary = pd.DataFrame(lst, columns=cols)\n",
    "    item_pareto_summary=item_pareto_summary.set_index(\"Brand\")\n",
    "    \n",
    "    summary_item_pareto_final = pd.concat([summary_item_pareto_final, summary_by_brand_df])\n",
    "#items_combined_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig SKU count</th>\n",
       "      <th>New SKU count</th>\n",
       "      <th>Other%(Billing)</th>\n",
       "      <th>Other%(Sales Qty)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brand</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B046</th>\n",
       "      <td>156</td>\n",
       "      <td>119</td>\n",
       "      <td>5.10</td>\n",
       "      <td>22.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B124</th>\n",
       "      <td>120</td>\n",
       "      <td>84</td>\n",
       "      <td>5.14</td>\n",
       "      <td>19.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B023</th>\n",
       "      <td>197</td>\n",
       "      <td>138</td>\n",
       "      <td>5.11</td>\n",
       "      <td>19.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B094</th>\n",
       "      <td>591</td>\n",
       "      <td>409</td>\n",
       "      <td>5.02</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B014</th>\n",
       "      <td>391</td>\n",
       "      <td>258</td>\n",
       "      <td>5.07</td>\n",
       "      <td>13.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Orig SKU count  New SKU count  Other%(Billing)  Other%(Sales Qty)\n",
       "Brand                                                                   \n",
       "B046              156            119             5.10              22.17\n",
       "B124              120             84             5.14              19.76\n",
       "B023              197            138             5.11              19.24\n",
       "B094              591            409             5.02              17.50\n",
       "B014              391            258             5.07              13.97"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_pareto_summary.sort_values(by = ['Other%(Sales Qty)'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>item_no</th>\n",
       "      <th>state</th>\n",
       "      <th>store_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>store_location</th>\n",
       "      <th>city_type</th>\n",
       "      <th>region</th>\n",
       "      <th>quantity</th>\n",
       "      <th>purchase_quantity</th>\n",
       "      <th>...</th>\n",
       "      <th>movement</th>\n",
       "      <th>material</th>\n",
       "      <th>dial_color</th>\n",
       "      <th>strap_type</th>\n",
       "      <th>strap_color</th>\n",
       "      <th>precious_stone</th>\n",
       "      <th>glass</th>\n",
       "      <th>case_shape</th>\n",
       "      <th>watch_type</th>\n",
       "      <th>area_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5103485</td>\n",
       "      <td>ST12</td>\n",
       "      <td>Summit</td>\n",
       "      <td>B027</td>\n",
       "      <td>Mall</td>\n",
       "      <td>Tier1</td>\n",
       "      <td>West</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>quartz</td>\n",
       "      <td>steel</td>\n",
       "      <td>white</td>\n",
       "      <td>steel</td>\n",
       "      <td>silver</td>\n",
       "      <td>no</td>\n",
       "      <td>sapphire crystal</td>\n",
       "      <td>square</td>\n",
       "      <td>analog</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>10</td>\n",
       "      <td>5161506</td>\n",
       "      <td>ST09</td>\n",
       "      <td>Summit</td>\n",
       "      <td>B027</td>\n",
       "      <td>Mall</td>\n",
       "      <td>Tier1</td>\n",
       "      <td>South</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>automatic</td>\n",
       "      <td>steel &amp; rose gold</td>\n",
       "      <td>black</td>\n",
       "      <td>rubber</td>\n",
       "      <td>black</td>\n",
       "      <td>no</td>\n",
       "      <td>sapphire crystal</td>\n",
       "      <td>round</td>\n",
       "      <td>analog</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>7</td>\n",
       "      <td>5168340</td>\n",
       "      <td>ST09</td>\n",
       "      <td>Summit</td>\n",
       "      <td>B027</td>\n",
       "      <td>Mall</td>\n",
       "      <td>Tier1</td>\n",
       "      <td>South</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>automatic</td>\n",
       "      <td>steel</td>\n",
       "      <td>silver</td>\n",
       "      <td>leather</td>\n",
       "      <td>black</td>\n",
       "      <td>no</td>\n",
       "      <td>sapphire crystal</td>\n",
       "      <td>round</td>\n",
       "      <td>analog</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>5</td>\n",
       "      <td>5182086</td>\n",
       "      <td>ST02</td>\n",
       "      <td>Ethos</td>\n",
       "      <td>B027</td>\n",
       "      <td>High Street</td>\n",
       "      <td>Tier2</td>\n",
       "      <td>North</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>automatic</td>\n",
       "      <td>steel</td>\n",
       "      <td>silver</td>\n",
       "      <td>leather</td>\n",
       "      <td>black</td>\n",
       "      <td>no</td>\n",
       "      <td>sapphire crystal</td>\n",
       "      <td>rectangle</td>\n",
       "      <td>analog</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>5</td>\n",
       "      <td>5119075</td>\n",
       "      <td>ST03</td>\n",
       "      <td>Summit</td>\n",
       "      <td>B027</td>\n",
       "      <td>Mall</td>\n",
       "      <td>Tier1</td>\n",
       "      <td>North</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>automatic</td>\n",
       "      <td>steel</td>\n",
       "      <td>silver</td>\n",
       "      <td>steel</td>\n",
       "      <td>silver</td>\n",
       "      <td>no</td>\n",
       "      <td>sapphire crystal</td>\n",
       "      <td>round</td>\n",
       "      <td>analog</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      period  item_no state store_type brand store_location city_type region  \\\n",
       "0          1  5103485  ST12     Summit  B027           Mall     Tier1   West   \n",
       "587       10  5161506  ST09     Summit  B027           Mall     Tier1  South   \n",
       "794        7  5168340  ST09     Summit  B027           Mall     Tier1  South   \n",
       "1616       5  5182086  ST02      Ethos  B027    High Street     Tier2  North   \n",
       "2534       5  5119075  ST03     Summit  B027           Mall     Tier1  North   \n",
       "\n",
       "      quantity  purchase_quantity  ...   movement           material  \\\n",
       "0            1                  0  ...     quartz              steel   \n",
       "587          1                  0  ...  automatic  steel & rose gold   \n",
       "794          1                  0  ...  automatic              steel   \n",
       "1616         1                  0  ...  automatic              steel   \n",
       "2534         0                  1  ...  automatic              steel   \n",
       "\n",
       "      dial_color  strap_type  strap_color precious_stone             glass  \\\n",
       "0          white       steel       silver             no  sapphire crystal   \n",
       "587        black      rubber        black             no  sapphire crystal   \n",
       "794       silver     leather        black             no  sapphire crystal   \n",
       "1616      silver     leather        black             no  sapphire crystal   \n",
       "2534      silver       steel       silver             no  sapphire crystal   \n",
       "\n",
       "     case_shape watch_type  area_code  \n",
       "0        square     analog          3  \n",
       "587       round     analog          6  \n",
       "794       round     analog          6  \n",
       "1616  rectangle     analog          1  \n",
       "2534      round     analog          2  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_item_pareto_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412140, 47)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2(a)(ii) Aggregating all \"Other\" SKUS into SKU per brand\n",
    "\n",
    "summarize_method = {\n",
    "        'brand' :'first', 'store_location' :'first',\n",
    "       'city_type' :'first', 'region' :'first', 'quantity' :'mean', 'purchase_quantity' :'mean',\n",
    "       'transfer_quantity' :'mean', 'available_quantity' :'mean', 'sales_quantity' :'mean',\n",
    "       'purchase_cost_amount' :'mean', 'purchase_mrp' :'mean', 'purchase_date' :'first',\n",
    "       'stock_prevailing_mrp' :'mean', 'store_in' :'first', 'product_group_code' :'first',\n",
    "       'transfer_cost_amount' :'mean', 'sales_department' :'first', 'days_to_sell' :'mean',\n",
    "       'num_of_customers' :'mean', 'total_price' :'mean', 'line_discount' :'mean', 'crm_line_discount' :'mean',\n",
    "       'discount' :'mean', 'tax' :'mean', 'cost' :'mean', 'billing' :'mean', 'contribution' :'mean', 'trade_incentive' :'mean',\n",
    "       'trade_incentive_value' :'mean', 'total_contribution' :'mean', 'case_size' :'mean',\n",
    "       'case_size_range' :'first', 'gender' :'first', 'movement' :'first', 'material' :'first', 'dial_color' :'first',\n",
    "       'strap_type' :'first', 'strap_color' :'first', 'precious_stone' :'first', 'glass' :'first', 'case_shape' :'first',\n",
    "       'watch_type' :'first', 'area_code' :'first'\n",
    "}\n",
    "\n",
    "\n",
    "sales_sum_df = summary_item_pareto_final.groupby(['store_type','item_no','period','state']).agg(summarize_method).reset_index()\n",
    "sales_sum_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Adding market share column {log S/So}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2(B)(i) - Adding log S/So\n",
    "\n",
    "#reading market shares\n",
    "market_share=pd.read_excel(data_path + \"market_share_encoded.xlsx\", header=0,index_col=0)\n",
    "\n",
    "#computing market size for each state-period\n",
    "market_sizes=sales_sum_df.groupby(['state','period']).agg({'sales_quantity':'sum'})\n",
    "market_sizes=market_sizes.reset_index()\n",
    "market_sizes=pd.merge(market_sizes,market_share, left_on='state', right_on='SubCode', how='left')#.drop('Attribute_x', axis=1)\n",
    "market_sizes['Market Size']=market_sizes['sales_quantity'].div(market_sizes['Market Share'], axis=0)\n",
    "\n",
    "#computing number of stores per state\n",
    "x=sales_sum_df.groupby(['state','period'])['store_type'].unique()\n",
    "l=[]\n",
    "store_nos=pd.DataFrame()\n",
    "for i in range(len(x)):\n",
    "    l.append([x.index[i][0],x.index[i][1],len(x[i])])\n",
    "cols=['state','period','Store numbers']\n",
    "store_nos = pd.DataFrame(l, columns=cols)\n",
    "\n",
    "#merging market sizes with number of stores per market\n",
    "market_sizes=pd.merge(market_sizes,store_nos, how='inner')\n",
    "\n",
    "#computing market size per store\n",
    "market_sizes['per store market']=market_sizes['Market Size']/market_sizes['Store numbers']\n",
    "\n",
    "#adding market share per store-period to the main data\n",
    "market_sizes=market_sizes[['state','period','per store market']]#extracting only relevant columns from market_sizes\n",
    "merge_cols=['state','period']\n",
    "summary_with_market_shares=pd.merge(sales_sum_df,market_sizes, on=merge_cols,how='inner')\n",
    "\n",
    "#computing So\n",
    "\n",
    "# summary_with_market_shares['so'] = summary_with_market_shares['per store type market']-summary_with_market_shares['sales_quantity']\n",
    "\n",
    "summary_with_market_shares['so']=summary_with_market_shares['per store market']-summary_with_market_shares['sales_quantity']\n",
    "summary_with_market_shares = summary_with_market_shares.fillna(0)[summary_with_market_shares['so'] != 0]\n",
    "\n",
    "#computing log(S/So) [replacing zeros with 1e-08 so that logs dont create a problem]\n",
    "summary_with_market_shares['so']=summary_with_market_shares['sales_quantity'].div(summary_with_market_shares['so'],axis=0)\n",
    "summary_with_market_shares['so'] = summary_with_market_shares['so'].replace(0,10**(-5))\n",
    "\n",
    "summary_with_market_shares['so']=np.log(summary_with_market_shares['so'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_quantity</th>\n",
       "      <th>per store market</th>\n",
       "      <th>so</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sales_quantity, per store market, so]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2(b)(ii) checking for NaNs\n",
    "d=summary_with_market_shares[['sales_quantity','per store market','so']]\n",
    "d[d.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_quantity</th>\n",
       "      <th>per store market</th>\n",
       "      <th>so</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sales_quantity, per store market, so]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2(b)(iii)checking for inf values\n",
    "d.iloc[d.index[np.isinf(d).any(1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Series([], Name: period, dtype: int64)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2(b)(iii) checking for inf values\n",
    "[summary_with_market_shares['period'].iloc[d.index[np.isinf(d).any(1)]].value_counts()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2(b)(iv) extracting specific columns\n",
    "\n",
    "col=[ 'item_no','period', 'state', 'region',\n",
    "       'brand', 'stock_prevailing_mrp', 'store_type', 'store_location', 'city_type', 'case_size_range',\n",
    "       'gender', 'movement', 'material', 'dial_color', 'strap_type',\n",
    "       'strap_color', 'precious_stone', 'glass', 'case_shape', 'watch_type','billing','sales_quantity','so']\n",
    "\n",
    "summary_final=summary_with_market_shares.loc[:,col]\n",
    "#df_north_final.fillna(0, inplace=True)\n",
    "\n",
    "summary_final['item_no']=summary_final['item_no'].astype(str)\n",
    "summary_final['period']=summary_final['period'].astype(int)\n",
    "summary_final['case_shape']=summary_final['case_shape'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_final = summary_final[summary_final['period'] != 14]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Performing Feature Pareto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a function for doing pareto analysis on features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function combines all levels of a categorical features that cummulatively account for ~10% or less by Sales billings into a new level called \"others\". Features with less than 10 levels are not considered for pareto analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto(df,cols):\n",
    "    lst=[]\n",
    "    feature_mapping={}\n",
    "    for col in cols:\n",
    "                \n",
    "        series=df.fillna(0).groupby([col]).agg({'billing':'sum'}).sort_values('billing',ascending=False)\n",
    "        mask=series.cumsum()/series.sum()>0.9 \n",
    "        mask=mask.iloc[:,0]\n",
    "        levels=len(df[col].unique())\n",
    "        \n",
    "        if levels>10:\n",
    "            df[col] = np.where(df[col].isin(series[mask].index),'Other',df[col])\n",
    "            feature_mapping[col]=series[mask].index.to_list()\n",
    "        new_levels=len(df[col].unique())\n",
    "                       \n",
    "        freq=df[col].value_counts()/df[col].value_counts().sum()*100\n",
    "        freq=freq.round(2)\n",
    "\n",
    "        sale_qty=df.groupby([col]).agg({'sales_quantity':'sum'}).sort_values('sales_quantity',ascending=False)\n",
    "        sale_qty=sale_qty/sale_qty.sum()*100\n",
    "        sale_qty=sale_qty.round(2)\n",
    "        try:\n",
    "            Other_Sales_Qty=sale_qty['sales_quantity']['Other']\n",
    "        except:\n",
    "            Other_Sales_Qty=0\n",
    "        \n",
    "        bill=df.groupby([col]).agg({'billing':'sum'}).sort_values('billing',ascending=False)\n",
    "        bill=bill/bill.sum()*100\n",
    "        bill=bill.round(2)\n",
    "        try:\n",
    "            Other_bill=bill['billing']['Other']\n",
    "        except:\n",
    "            Other_bill=0\n",
    "        \n",
    "        #comparison=mrp.merge(sale_qty, left_index=True, right_index=True)\n",
    "        lst.append([col.upper(),levels, new_levels,Other_bill,Other_Sales_Qty])\n",
    "        #print (\"%s-Originally %d levels,combined %d levels into 'Other'.New Levels %d.By MRP,Other is %2.1f and by sale qty others is %2.1f\"%(col.upper(),levels, levels-new_levels, new_levels,mrp['stock_prevailing_mrp']['Other'],sale_qty['sales_quantity']['Other']))\n",
    "    \n",
    "    cols=['Feature', 'Orig Levels', 'New Levels', 'Other%(Billing)', 'Other%(Sales Qty)']\n",
    "    df1 = pd.DataFrame(lst, columns=cols)\n",
    "    df1=df1.set_index(\"Feature\")\n",
    "    \n",
    "    return df1,df, feature_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig Levels</th>\n",
       "      <th>New Levels</th>\n",
       "      <th>Other%(Billing)</th>\n",
       "      <th>Other%(Sales Qty)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CASE_SIZE_RANGE</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>11.03</td>\n",
       "      <td>15.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GENDER</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOVEMENT</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MATERIAL</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>11.96</td>\n",
       "      <td>14.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIAL_COLOR</th>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>11.28</td>\n",
       "      <td>10.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STRAP_TYPE</th>\n",
       "      <td>60</td>\n",
       "      <td>8</td>\n",
       "      <td>11.57</td>\n",
       "      <td>16.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STRAP_COLOR</th>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>11.04</td>\n",
       "      <td>24.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRECIOUS_STONE</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLASS</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASE_SHAPE</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WATCH_TYPE</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Orig Levels  New Levels  Other%(Billing)  Other%(Sales Qty)\n",
       "Feature                                                                     \n",
       "CASE_SIZE_RANGE           13           7            11.03              15.61\n",
       "GENDER                     3           3             0.00               0.00\n",
       "MOVEMENT                   6           6             0.00               0.00\n",
       "MATERIAL                  56           7            11.96              14.47\n",
       "DIAL_COLOR                46           9            11.28              10.44\n",
       "STRAP_TYPE                60           8            11.57              16.31\n",
       "STRAP_COLOR               44           7            11.04              24.60\n",
       "PRECIOUS_STONE             8           8             0.00               0.00\n",
       "GLASS                      7           7             0.00               0.00\n",
       "CASE_SHAPE                 6           6             0.00               0.00\n",
       "WATCH_TYPE                 6           6             0.00               0.00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#cols=['brand','case_size', 'case_size_range', 'gender', 'material', 'dial_color', 'strap_type', 'strap_color','precious_stone', 'glass', 'watch_type']\n",
    "cols=['case_size_range', 'gender','movement', 'material', 'dial_color', 'strap_type', 'strap_color','precious_stone', 'glass', 'case_shape', 'watch_type']\n",
    "\n",
    "#cols=['case_size_range']\n",
    "summary,summary_final_pareto,feature_mapping_dict=pareto(summary_final, cols)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Building a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retaining only 0 and 1 for sales_quantity\n",
    "summary_final_classifier = pd.DataFrame()\n",
    "summary_final_classifier = pd.concat([summary_final_classifier, summary_final_pareto])\n",
    "summary_final_classifier['sales_class'] = np.where(summary_final_classifier['sales_quantity'] > 0,True,False)         \n",
    "#summary_final_classifier['sales_quantity'].value_counts().sort_index()\n",
    "#summary_final_classifier.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_no', 'period', 'state', 'region', 'brand', 'stock_prevailing_mrp',\n",
       "       'store_type', 'store_location', 'city_type', 'case_size_range',\n",
       "       'gender', 'movement', 'material', 'dial_color', 'strap_type',\n",
       "       'strap_color', 'precious_stone', 'glass', 'case_shape', 'watch_type',\n",
       "       'billing', 'sales_quantity', 'so', 'sales_class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_final_classifier.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variables\n",
    "cols=['brand','state','region', 'store_type', 'store_location', 'city_type',\n",
    "       'case_size_range', 'gender', 'movement', 'material', 'dial_color',\n",
    "       'strap_type', 'strap_color', 'precious_stone', 'glass', 'case_shape',\n",
    "       'watch_type']\n",
    "summary_final_classifier_dummies=pd.get_dummies(data=summary_final_classifier, columns=cols)\n",
    "\n",
    "#for sales_quantity as the target variable\n",
    "#creating seperate df for independent and dependent features\n",
    "y_clf=summary_final_classifier_dummies.loc[:, summary_final_classifier_dummies.columns == 'sales_class']\n",
    "X_clf=summary_final_classifier_dummies.drop(columns =['sales_quantity','item_no','billing','so', 'sales_class'])\n",
    "\n",
    "#performing train and test split on data\n",
    "X_train_clf,X_test_clf, y_train_clf, y_test_clf = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for duplicate column names\n",
    "duplicate_columns = summary_final_classifier_dummies.columns[summary_final_classifier_dummies.columns.duplicated()]\n",
    "duplicate_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting by week_no and year\n",
    "#df_north_pareto=df_north_pareto.sort_values(['week_no', 'year'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variables\n",
    "#cols=['brand','state','region', 'store_type', 'store_location', 'city_type',\n",
    "#       'case_size_range', 'gender', 'movement', 'material', 'dial_color',\n",
    "#       'strap_type', 'strap_color', 'precious_stone', 'glass', 'case_shape',\n",
    "#       'watch_type', 'week_no', 'year']\n",
    "#df_north_dummies=pd.get_dummies(data=df_north_pareto, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sales_quantity as the target variable\n",
    "#creating seperate df for independent and dependent features\n",
    "#y=df_north_dummies.loc[:, df_north_dummies.columns == 'sales_quantity']\n",
    "#X=df_north_dummies.drop(columns =['available_quantity','sales_quantity','location_code','item_no','billing','so'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for So as the target variable\n",
    "#creating seperate df for independent and dependent features\n",
    "#y=df_north_dummies.loc[:, df_north_dummies.columns == 'so']\n",
    "#X=df_north_dummies.drop(columns =['available_quantity','sales_quantity','location_code','item_no','billing','so'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing train and test split on data\n",
    "\n",
    "#split=0.2\n",
    "#test=int(len(X)*split)\n",
    "#train=len(X)-test\n",
    "#X_train=X.head(train)\n",
    "#y_train=y.head(train)\n",
    "#X_test=X.tail(test)\n",
    "#y_test=y.tail(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variables\n",
    "#cols=['brand','state','region', 'store_type', 'store_location', 'city_type',\n",
    "#       'case_size_range', 'gender', 'movement', 'material', 'dial_color',\n",
    "#       'strap_type', 'strap_color', 'precious_stone', 'glass', 'case_shape',\n",
    "#       'watch_type', 'week_no', 'year']\n",
    "#df_north_dummies_clf=pd.get_dummies(data=df_north_pareto_classifier, columns=cols)\n",
    "\n",
    "#for sales_quantity as the target variable\n",
    "#creating seperate df for independent and dependent features\n",
    "#y_clf=df_north_dummies_clf.loc[:, df_north_dummies_clf.columns == 'sales_quantity']\n",
    "#X_clf=df_north_dummies_clf.drop(columns =['sales_quantity','location_code','item_no','billing','so'])\n",
    "\n",
    "#performing train and test split on data\n",
    "\n",
    "#split=0.2\n",
    "#test_clf=int(len(X_clf)*split)\n",
    "#train_clf=len(X_clf)-test_clf\n",
    "#X_train_clf=X_clf.head(train_clf)\n",
    "#y_train_clf=y_clf.head(train_clf)\n",
    "#X_test_clf=X_clf.tail(test_clf)\n",
    "#y_test_clf=y_clf.tail(test_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U imbalanced-learn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=11915027)\n",
    "X_bal_clf, y_bal_clf = ros.fit_resample(X_train_clf, y_train_clf)\n",
    "#classifier(X_bal,y_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312123 447014 312123 447014\n"
     ]
    }
   ],
   "source": [
    "print (len(X_train_clf),len(X_bal_clf),len(y_train_clf),len(y_bal_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before Balancing</th>\n",
       "      <th>After Balancing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>223507</td>\n",
       "      <td>223507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>88616</td>\n",
       "      <td>223507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Before Balancing  After Balancing\n",
       "False            223507           223507\n",
       "True              88616           223507"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts=y_train_clf.iloc[:, 0].value_counts().to_frame(name='Before Balancing')\n",
    "count1= pd.DataFrame(np.bincount(y_bal_clf.iloc[:, 0]))\n",
    "counts['After Balancing'] = count1\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining function for computing confusion metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function for computing confusion metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def cfm(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    tnp=tn/(tn+fp)*100\n",
    "    fpp=fp/(tn+fp)*100\n",
    "    fnp=fn/(fn+tp)*100\n",
    "    tpp=tp/(fn+tp)*100\n",
    "    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "    accuracy=metrics.accuracy_score(y_test, y_pred)*100\n",
    "    return accuracy,tnp,fpp,fnp,tpp,roc_auc\n",
    "    #return accuracy,tn,fp,fn,tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Regression model on non-zero sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slicing for data with 1s as target variable\n",
    "summary_final_pareto_reg = summary_final_pareto[summary_final_pareto['sales_quantity'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#creating dummy variables\n",
    "cols=['brand','state','region', 'store_type', 'store_location', 'city_type',\n",
    "       'case_size_range', 'gender', 'movement', 'material', 'dial_color',\n",
    "       'strap_type', 'strap_color', 'precious_stone', 'glass', 'case_shape',\n",
    "       'watch_type']\n",
    "summary_final_dummies=pd.get_dummies(data=summary_final_pareto_reg, columns=cols)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110602, 191)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_final_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for duplicate column names\n",
    "duplicate_columns = summary_final_dummies.columns[summary_final_dummies.columns.duplicated()]\n",
    "duplicate_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for So as the target variable\n",
    "#creating seperate df for independent and dependent features\n",
    "y=summary_final_dummies.loc[:, summary_final_dummies.columns == 'so']\n",
    "X=summary_final_dummies.drop(columns =['sales_quantity','item_no','billing', 'so'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsplit=0.2\\ntest=int(len(X)*split)\\ntrain=len(X)-test\\nX_train=X.head(train)\\ny_train=y.head(train)\\nX_test=X.tail(test)\\ny_test=y.tail(test)\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing train and test split on data\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "split=0.2\n",
    "test=int(len(X)*split)\n",
    "train=len(X)-test\n",
    "X_train=X.head(train)\n",
    "y_train=y.head(train)\n",
    "X_test=X.tail(test)\n",
    "y_test=y.tail(test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model based on the output of random_search.best_estimator_\n",
    "best_gb=xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
    "             colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.1, max_delta_step=0, max_depth=12,\n",
    "             min_child_weight = 7, missing=np.nan,\n",
    "              n_estimator=3, n_estimators=100,\n",
    "             n_jobs=0, num_parallel_tree=1, objective='reg:squarederror',\n",
    "             random_state=0, reg_alpha=0.5, reg_lambda=0.3, scale_pos_weight=1,\n",
    "             subsample=0.2, tree_method='exact', validate_parameters=1,\n",
    "             verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression RMSE: 0.49, Test R2: 0.67\n"
     ]
    }
   ],
   "source": [
    "#running the regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg_model_so = LinearRegression()  \n",
    "reg_model_so.fit(X_train, y_train)\n",
    "preds_so = reg_model_so.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds_so))\n",
    "r2=r2_score(y_test, preds_so)\n",
    "print(\"Linear regression RMSE: %.2f, Test R2: %.2f\" % (rmse,r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Predictions on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the store, brand and period for which the assortment is being developed\n",
    "store = 'S28'\n",
    "period=14\n",
    "brand='B063'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtaining unique SKUs\n",
    "cols_for_unique_selection = [\"item_no\",\"brand\",\"case_size_range\",\"gender\",\"movement\",\"material\",\"dial_color\",\"strap_type\",\n",
    "        \"strap_color\",\"precious_stone\",\"glass\",\"case_shape\",\"watch_type\"]\n",
    "                             \n",
    "unique_sku=summary_df[cols_for_unique_selection].drop_duplicates(cols_for_unique_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace features from pareto\n",
    "cols=['case_size_range', 'material', 'dial_color', 'strap_type', 'strap_color']\n",
    "for col in cols:\n",
    "    unique_sku[col] = np.where(unique_sku[col].isin(feature_mapping_dict[col]),'Other',unique_sku[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace items with Others - replace brands first\n",
    "unique_sku['brand'] = np.where(unique_sku['item_no'].isin(item_mapping_list),'Others',unique_sku['brand'])\n",
    "unique_sku['item_no'] = np.where(unique_sku['item_no'].isin(item_mapping_list),'Others',unique_sku['item_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding latest MRPs\n",
    "item_mrp = pd.read_excel(\"D:\\\\Backup\\\\ISB CBA\\\\Capstone\\\\itemMRP_encoded.xlsx\")\n",
    "item_mrp['item_no'] = np.where(item_mrp['item_no'].isin(item_mapping_list),'Others',item_mrp['item_no'])\n",
    "item_mrp['brand'] = np.where(item_mrp['item_no'].isin(item_mapping_list),'Others',item_mrp['brand'])\n",
    "item_mrp = item_mrp.rename(columns={\"MRP\": \"stock_prevailing_mrp\"})\n",
    "item_mrp_agg = item_mrp.groupby(['item_no', 'brand']).agg({'stock_prevailing_mrp':'mean'}).reset_index()\n",
    "unique_sku = unique_sku.merge(item_mrp_agg, left_on=['item_no'], right_on=['item_no'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for nulls\n",
    "item_mrp_agg.columns[item_mrp_agg.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_no', 'case_size_range', 'gender', 'movement', 'material',\n",
       "       'dial_color', 'strap_type', 'strap_color', 'precious_stone', 'glass',\n",
       "       'case_shape', 'watch_type', 'brand', 'stock_prevailing_mrp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sku=unique_sku.drop(['brand_x'],axis=1)\n",
    "unique_sku.rename(columns={'brand_y': 'brand'}, inplace=True)\n",
    "unique_sku.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brand', 'stock_prevailing_mrp']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to be removed\n",
    "unique_sku.columns[unique_sku.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be removed\n",
    "unique_sku = unique_sku.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variables\n",
    "cols=['brand','case_size_range', 'gender', 'movement', 'material', 'dial_color',\n",
    "       'strap_type', 'strap_color', 'precious_stone', 'glass', 'case_shape',\n",
    "       'watch_type']\n",
    "unique_sku_dummies=pd.get_dummies(data=unique_sku, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding store dummies\n",
    "store_master = pd.read_csv(\"D:\\\\Backup\\\\ISB CBA\\\\Capstone\\\\store_master_with_state_and_regions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_ST12\n",
      "region_West\n",
      "store_type_Ethos\n",
      "store_location_Mall\n",
      "city_type_Tier1\n"
     ]
    }
   ],
   "source": [
    "#adding store dummies\n",
    "store_dummies = [\n",
    "    'state_ST02', 'state_ST03', 'state_ST05', 'state_ST07', 'state_ST09', 'state_ST12', 'state_ST13', 'state_ST15', 'state_ST16', \n",
    "    'state_ST17', 'state_ST19', 'state_ST21', 'state_ST24', 'state_ST28', 'region_East', 'region_North', 'region_South',\n",
    "'region_West', 'store_type_Ethos', 'store_type_Large', 'store_type_Summit', 'store_location_Airport', 'store_location_DFS', \n",
    "    'store_location_High Street', 'store_location_Mall', 'city_type_Tier1', 'city_type_Tier2'\n",
    "]\n",
    "\n",
    "for col in store_dummies:\n",
    "    unique_sku_dummies[col] = 0\n",
    "    \n",
    "#Modifying dummy values for store attributes\n",
    "store_master = pd.read_csv(\"D:\\\\Backup\\\\ISB CBA\\\\Capstone\\\\store_master_with_state_and_regions.csv\")\n",
    "store_cols = [\"state\",\"region\",\"store_type\",\"store_location\",\"city_type\"]\n",
    "for col in store_cols:\n",
    "    dummy_col_name = col + '_' + store_master[store_master['store_code'] == store][col].unique()[0]\n",
    "    print(dummy_col_name)\n",
    "    unique_sku_dummies[dummy_col_name] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160316, 204)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sku_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check\n",
    "unique_sku_dummies['brand_Others'] = 0\n",
    "unique_sku_dummies['period'] = period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of missing dummies:  0\n",
      "No. of new dummies:  17\n"
     ]
    }
   ],
   "source": [
    "#checking that all dummy columns are created\n",
    "X_data=unique_sku_dummies.drop(columns =['item_no'])\n",
    "missing_dummies = set(X_train_clf) - set(X_data)\n",
    "additional_dummies = set(X_data) - set(X_train_clf)\n",
    "print ('No. of missing dummies: ', len(missing_dummies))\n",
    "print ('No. of new dummies: ', len(additional_dummies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160316, 205)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data=unique_sku_dummies.drop(columns =['item_no'])\n",
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160316, 188)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the additional dummies\n",
    "#missing_dummies_cols = list(missing_dummies_set)\n",
    "for col in additional_dummies:\n",
    "    X_data = X_data.drop(columns = [col])\n",
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the classifer model on the data\n",
    "X_data=X_data[X_bal_clf.columns] # to get the column order as per training\n",
    "y_pred= xgb_model.predict(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending classifier prediction to unique skus\n",
    "#unique_sku_dummies['sales_class'] = y_pred\n",
    "#unique_sku_pred = unique_sku\n",
    "#unique_sku_pred['sales_class'] = y_pred\n",
    "#unique_sku_pred['sales_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining items that are predicted for sales\n",
    "#items_classified_for_sales = unique_sku_dummies[unique_sku_dummies['sales_class']]['item_no'].unique()\n",
    "#len(items_classified_for_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0 160315]\n",
      " [     1      1]]\n"
     ]
    }
   ],
   "source": [
    "#how many SKUs predicted as non zero\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing data for non-zero predictions (to run the regression model)\n",
    "X_data_non_zero=X_data[y_pred==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>stock_prevailing_mrp</th>\n",
       "      <th>brand_B007</th>\n",
       "      <th>brand_B008</th>\n",
       "      <th>brand_B010</th>\n",
       "      <th>brand_B013</th>\n",
       "      <th>brand_B014</th>\n",
       "      <th>brand_B017</th>\n",
       "      <th>brand_B018</th>\n",
       "      <th>brand_B020</th>\n",
       "      <th>...</th>\n",
       "      <th>case_shape_rectangle</th>\n",
       "      <th>case_shape_round</th>\n",
       "      <th>case_shape_square</th>\n",
       "      <th>case_shape_tonneau</th>\n",
       "      <th>watch_type_activity tracker</th>\n",
       "      <th>watch_type_analog</th>\n",
       "      <th>watch_type_analog-digital</th>\n",
       "      <th>watch_type_digital</th>\n",
       "      <th>watch_type_hybrid smart watch</th>\n",
       "      <th>watch_type_smart watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>14</td>\n",
       "      <td>349600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      period  stock_prevailing_mrp  brand_B007  brand_B008  brand_B010  \\\n",
       "2676      14              349600.0           0           0           0   \n",
       "\n",
       "      brand_B013  brand_B014  brand_B017  brand_B018  brand_B020  ...  \\\n",
       "2676           0           0           0           0           0  ...   \n",
       "\n",
       "      case_shape_rectangle  case_shape_round  case_shape_square  \\\n",
       "2676                     0                 1                  0   \n",
       "\n",
       "      case_shape_tonneau  watch_type_activity tracker  watch_type_analog  \\\n",
       "2676                   0                            0                  1   \n",
       "\n",
       "      watch_type_analog-digital  watch_type_digital  \\\n",
       "2676                          0                   0   \n",
       "\n",
       "      watch_type_hybrid smart watch  watch_type_smart watch  \n",
       "2676                              0                       0  \n",
       "\n",
       "[1 rows x 188 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_non_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying regression model on items that are predicted to sell\n",
    "\n",
    "\n",
    "#unique_sku_dummies_so = unique_sku_dummies[unique_sku_dummies['item_no'].isin(items_classified_for_sales)]\n",
    "#unique_sku_dummies_so = unique_sku_dummies[unique_sku_dummies['item_no'].isin(items_classified_for_sales)]\n",
    "#X_data_so = unique_sku_dummies_so.drop(columns =['item_no'])\n",
    "#X_data_so = unique_sku_dummies.drop(columns =['item_no'])#this line to be removed\n",
    "#X_data_so.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_dummies_set = set(X_data_so) - set(X_train2)\n",
    "#print(missing_dummies_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_data_so = X_data_so.drop(columns = list(missing_dummies_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_dummies_set = set(X_train2) - set(X_data_so)\n",
    "#print(missing_dummies_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 187 is different from 188)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-2e2376ab5064>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_non_zero\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_model_so\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data_so\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredictions_for_store\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_sku_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munique_sku_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sales_class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredictions_for_store\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'so'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpred_non_zero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Backup\\Anaconda1\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Backup\\Anaconda1\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m--> 220\u001b[1;33m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Backup\\Anaconda1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Backup\\Anaconda1\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 187 is different from 188)"
     ]
    }
   ],
   "source": [
    "pred_non_zero = reg_model_so.predict(X_data_non_zero)\n",
    "predictions_for_store = unique_sku_pred[unique_sku_pred['sales_class']]\n",
    "predictions_for_store['so'] = np.concatenate( pred_non_zero, axis=0 ).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-77-dc0abbbf6f37>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-77-dc0abbbf6f37>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    predictions_for_store['so']=\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "predictions_for_store['so']="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the Assortment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice prediction for store and brand\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####To change\n",
    "\n",
    "#Compute profit per SKU of the brand for the store\n",
    "profit=pd.read_excel (\"D:\\\\Backup\\\\ISB CBA\\\\Capstone\\\\profit_computation_S28.xlsx\", sheet_name='Sheet1',header=0)\n",
    "profit=profit[['item_no','Net Profit per unit']]\n",
    "profit=profit.set_index('item_no')\n",
    "profit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this code to be used when actual predictions are available, Till then use random predictions in the next cell\n",
    "\n",
    "\n",
    "#predicted log S/So\n",
    "#pred_log_s=pd.read_csv(\"D:\\\\Backup\\\\ISB CBA\\\\Capstone\\\\greedy_input.csv\")\n",
    "#pred_log_s=pred_log_s[['SKU','Ln (S/ So)']]\n",
    "#pred_log_s=pred_log_s.set_index('SKU')\n",
    "#pred_log_s['exp'] = np.exp(pred_log_s['Ln (S/ So)'])\n",
    "#pred_log_s['S']=market_size/(1+pred_log_s['exp'])*pred_log_s['exp']\n",
    "#pred_log_s=pd.merge(pred_log_s,profit,left_index=True,right_index=True)\n",
    "#pred_log_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating random predictions. Using the item MRP file for obtaining the unique SKUs\n",
    "\n",
    "pred_log_s= pd.read_excel(\"D:\\\\Backup\\\\ISB CBA\\\\Capstone\\\\itemMRP_encoded.xlsx\")\n",
    "pred_log_s['Ln (S/ So)']=np.random.rand(len(pred_log_s))*(-20)# random predictions\n",
    "pred_log_s=pred_log_s.drop(['MRP'],axis=1)#deleting MRPs\n",
    "pred_log_s=pred_log_s.set_index('item_no')\n",
    "pred_log_s['exp'] = np.exp(pred_log_s['Ln (S/ So)'])# taking exponent\n",
    "pred_log_s['S']=market_size/(1+pred_log_s['exp'])*pred_log_s['exp']#calculating predicted sale qty\n",
    "pred_log_s=pd.merge(pred_log_s,profit,left_index=True,right_index=True)#merging with profit df to get profit column. \n",
    "                                                                       #Also helps in culling dthe unique SKUs to only \n",
    "                                                                       #those which are retailed in specific store\n",
    "pred_log_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define greedy algorthim function\n",
    "def assortment (predictions, size):\n",
    "    assortment_size=size\n",
    "    for i in range(assortment_size):\n",
    "        i+=1\n",
    "        #print (i)\n",
    "        best_profit=0\n",
    "        if i==1:\n",
    "            best_selection=pd.DataFrame(columns=predictions.columns)\n",
    "        #print (predictions.index)\n",
    "        for sku in predictions.index:\n",
    "            #print (sku)\n",
    "            testing=best_selection\n",
    "            if sku not in testing.index:\n",
    "                row=predictions.loc[sku]\n",
    "                testing=testing.append(row)\n",
    "                testing['S']=market_size/(1+testing['exp'].sum())*predictions['exp']\n",
    "                testing['Profit']=testing['S'].mul(testing['Net Profit per unit'],axis=0)\n",
    "                if best_profit<=testing['Profit'].sum():\n",
    "                    best_profit=testing['Profit'].sum()\n",
    "                    candidate=testing\n",
    "            else:\n",
    "                continue\n",
    "        best_selection=candidate\n",
    "    #return best_selection['Profit'].sum().round(0)\n",
    "    best_selection=best_selection.reset_index()\n",
    "    best_selection.loc['Total']= best_selection.sum()\n",
    "    return best_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an assortment for 50 skus for brand B063\n",
    "pred_log_s_brand=pred_log_s[pred_log_s['brand']==brand]\n",
    "assortment(pred_log_s_brand, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
