{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476711, 47)\n",
      "476711\n"
     ]
    }
   ],
   "source": [
    "dirpath = '/Users/parulgaba/Desktop/Capstone-Ethos/ConfidentialData/csvdata/'\n",
    "\n",
    "data_path = '/Users/parulgaba/Desktop/Capstone-Ethos/ethos-retail-model/data/'\n",
    "\n",
    "filename = data_path + 'regression_data/' + 'aggregated_summary_store_type_12_weeks.csv'\n",
    "chunksize = 10 ** 5\n",
    "rows=0\n",
    "summary_df = pd.DataFrame()\n",
    "for chunk in pd.read_csv(filename, chunksize=chunksize):\n",
    "    summary_df=pd.concat([summary_df,chunk])\n",
    "    rows+=chunk.shape[0]\n",
    "    \n",
    "summary_df.fillna(0)\n",
    "print(summary_df.shape)\n",
    "print (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df['stock_prevailing_mrp'] = summary_df['stock_prevailing_mrp'].div(10000)\n",
    "summary_df['billing'] = summary_df['billing'].div(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique items removed with no sales at all for all 3 three years : 4324\n"
     ]
    }
   ],
   "source": [
    "items_no_sales = summary_df.groupby(['item_no']).agg({'sales_quantity':'sum'}).reset_index()\n",
    "unique_item_no_sales = items_no_sales[items_no_sales['sales_quantity'] == 0]['item_no'].unique()\n",
    "summary_df = summary_df[~summary_df['item_no'].isin(unique_item_no_sales)]\n",
    "print(\"Unique items removed with no sales at all for all 3 three years : \" + str(len(unique_item_no_sales)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438196, 47)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df['item_no']=summary_df['item_no'].astype(str)\n",
    "summary_df['period']=summary_df['period'].astype(str)\n",
    "summary_df['case_shape']=summary_df['case_shape'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = summary_df['brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14749\n"
     ]
    }
   ],
   "source": [
    "print (len(summary_df['item_no'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cols = ['case_size_range', 'gender','movement', 'material', 'dial_color', 'strap_type', 'strap_color','precious_stone', 'glass', 'case_shape', 'watch_type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df with Other items\n",
    "\n",
    "summary_item_pareto_final = pd.DataFrame()\n",
    "list = []\n",
    "\n",
    "for brand in brands:\n",
    "    items_combined_df = pd.DataFrame()\n",
    "    summary_by_brand_df = summary_df[summary_df['brand'] == brand]\n",
    "    item_series = summary_by_brand_df.fillna(0).groupby('item_no').agg({'sales_quantity':'sum'}).sort_values('sales_quantity',ascending=False)\n",
    "    items_combined_df = pd.concat([items_combined_df, item_series])\n",
    "    \n",
    "    mask=items_combined_df.cumsum()/items_combined_df.sum()>0.95\n",
    "    mask=mask.iloc[:,0]\n",
    "    \n",
    "    levels=len(summary_by_brand_df['item_no'].unique())\n",
    "    \n",
    "    summary_by_brand_df['brand'] = np.where(summary_by_brand_df['item_no'].isin(item_series[mask].index),'Other',summary_by_brand_df['brand'])         \n",
    "    summary_by_brand_df['item_no'] = np.where(summary_by_brand_df['item_no'].isin(item_series[mask].index),'Other',summary_by_brand_df['item_no'])\n",
    "    \n",
    "    for col in item_cols:\n",
    "        summary_by_brand_df[col] = np.where(summary_by_brand_df['item_no'].isin(item_series[mask].index),'Other',summary_by_brand_df[col])\n",
    "    \n",
    "    new_levels=len(summary_by_brand_df['item_no'].unique())\n",
    "    \n",
    "    freq=summary_by_brand_df['item_no'].value_counts()/summary_by_brand_df['item_no'].value_counts().sum()*100\n",
    "    freq=freq.round(2)\n",
    "    \n",
    "    sale_qty=summary_by_brand_df.groupby(['item_no']).agg({'sales_quantity':'sum'}).sort_values('sales_quantity',ascending=False)\n",
    "    sale_qty=sale_qty/sale_qty.sum()*100\n",
    "    sale_qty=sale_qty.round(2)\n",
    "    \n",
    "    try:\n",
    "        Other_Sales_Qty=sale_qty['sales_quantity']['Other']\n",
    "    except:\n",
    "        Other_Sales_Qty=0\n",
    "    bill=summary_by_brand_df.groupby(['item_no']).agg({'billing':'sum'}).sort_values('billing',ascending=False)\n",
    "    bill=bill/bill.sum()*100\n",
    "    bill=bill.round(2)\n",
    "    try:\n",
    "        Other_bill=bill['billing']['Other']\n",
    "    except:\n",
    "        Other_bill=0\n",
    "        \n",
    "    list.append([brand, levels, new_levels,Other_bill,Other_Sales_Qty])\n",
    "    \n",
    "    cols=['Brand', 'Orig SKU count', 'New SKU count', 'Other%(Billing)', 'Other%(Sales Qty)']\n",
    "    item_pareto_summary = pd.DataFrame(list, columns=cols)\n",
    "    item_pareto_summary=item_pareto_summary.set_index(\"Brand\")\n",
    "    \n",
    "    summary_item_pareto_final = pd.concat([summary_item_pareto_final, summary_by_brand_df])\n",
    "#items_combined_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9706\n"
     ]
    }
   ],
   "source": [
    "print (len(summary_item_pareto_final['item_no'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orig SKU count</th>\n",
       "      <th>New SKU count</th>\n",
       "      <th>Other%(Billing)</th>\n",
       "      <th>Other%(Sales Qty)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brand</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B027</th>\n",
       "      <td>97</td>\n",
       "      <td>83</td>\n",
       "      <td>9.68</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B033</th>\n",
       "      <td>69</td>\n",
       "      <td>63</td>\n",
       "      <td>6.75</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B063</th>\n",
       "      <td>670</td>\n",
       "      <td>397</td>\n",
       "      <td>16.49</td>\n",
       "      <td>5.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B083</th>\n",
       "      <td>789</td>\n",
       "      <td>389</td>\n",
       "      <td>26.09</td>\n",
       "      <td>5.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B100</th>\n",
       "      <td>1045</td>\n",
       "      <td>542</td>\n",
       "      <td>21.48</td>\n",
       "      <td>5.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Orig SKU count  New SKU count  Other%(Billing)  Other%(Sales Qty)\n",
       "Brand                                                                   \n",
       "B027               97             83             9.68               5.00\n",
       "B033               69             63             6.75               5.15\n",
       "B063              670            397            16.49               5.02\n",
       "B083              789            389            26.09               5.02\n",
       "B100             1045            542            21.48               5.02"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_pareto_summary.sort_values(by = ['Other%(Billing)']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62768, 47)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_item_pareto_final[summary_item_pareto_final['item_no'] == 'Other'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['period', 'item_no', 'state', 'store_type', 'brand', 'store_location',\n",
       "       'city_type', 'region', 'quantity', 'purchase_quantity',\n",
       "       'transfer_quantity', 'available_quantity', 'sales_quantity',\n",
       "       'purchase_cost_amount', 'purchase_mrp', 'purchase_date',\n",
       "       'stock_prevailing_mrp', 'store_in', 'product_group_code',\n",
       "       'transfer_cost_amount', 'sales_department', 'days_to_sell',\n",
       "       'num_of_customers', 'total_price', 'line_discount', 'crm_line_discount',\n",
       "       'discount', 'tax', 'cost', 'billing', 'contribution', 'trade_incentive',\n",
       "       'trade_incentive_value', 'total_contribution', 'case_size',\n",
       "       'case_size_range', 'gender', 'movement', 'material', 'dial_color',\n",
       "       'strap_type', 'strap_color', 'precious_stone', 'glass', 'case_shape',\n",
       "       'watch_type', 'area_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_item_pareto_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375664, 47)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_method = {\n",
    "         'brand' :'first', 'store_location' :'first',\n",
    "       'city_type' :'first', 'region' :'first', 'quantity' :'mean', 'purchase_quantity' :'mean',\n",
    "       'transfer_quantity' :'mean', 'available_quantity' :'mean', 'sales_quantity' :'mean',\n",
    "       'purchase_cost_amount' :'mean', 'purchase_mrp' :'mean', 'purchase_date' :'first',\n",
    "       'stock_prevailing_mrp' :'mean', 'store_in' :'first', 'product_group_code' :'first',\n",
    "       'transfer_cost_amount' :'mean', 'sales_department' :'first', 'days_to_sell' :'mean',\n",
    "       'num_of_customers' :'mean', 'total_price' :'mean', 'line_discount' :'mean', 'crm_line_discount' :'mean',\n",
    "       'discount' :'mean', 'tax' :'mean', 'cost' :'mean', 'billing' :'mean', 'contribution' :'mean', 'trade_incentive' :'mean',\n",
    "       'trade_incentive_value' :'mean', 'total_contribution' :'mean', 'case_size' :'mean',\n",
    "       'case_size_range' :'first', 'gender' :'first', 'movement' :'first', 'material' :'first', 'dial_color' :'first',\n",
    "       'strap_type' :'first', 'strap_color' :'first', 'precious_stone' :'first', 'glass' :'first', 'case_shape' :'first',\n",
    "       'watch_type' :'first', 'area_code' :'first'\n",
    "}\n",
    "\n",
    "\n",
    "sales_sum_df = summary_item_pareto_final.groupby(['store_type','item_no','period','state']).agg(summarize_method).reset_index()\n",
    "sales_sum_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding log S/So - Location code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading market shares\n",
    "market_share=pd.read_excel(data_path + \"market_share_encoded.xlsx\", header=0,index_col=0)\n",
    "\n",
    "#computing market size for each state-period\n",
    "market_sizes=sales_sum_df.groupby(['state','period']).agg({'sales_quantity':'sum'})\n",
    "market_sizes=market_sizes.reset_index()\n",
    "market_sizes=pd.merge(market_sizes,market_share, left_on='state', right_on='SubCode', how='left')#.drop('Attribute_x', axis=1)\n",
    "market_sizes['Market Size']=market_sizes['sales_quantity'].div(market_sizes['Market Share'], axis=0)\n",
    "\n",
    "#computing number of stores per state\n",
    "x=sales_sum_df.groupby(['state','period'])['store_type'].unique()\n",
    "l=[]\n",
    "store_nos=pd.DataFrame()\n",
    "for i in range(len(x)):\n",
    "    l.append([x.index[i][0],x.index[i][1],len(x[i])])\n",
    "cols=['state','period','Store numbers']\n",
    "store_nos = pd.DataFrame(l, columns=cols)\n",
    "\n",
    "#merging market sizes with number of stores per market\n",
    "market_sizes=pd.merge(market_sizes,store_nos, how='inner')\n",
    "\n",
    "#computing market size per store\n",
    "market_sizes['per store market']=market_sizes['Market Size']/market_sizes['Store numbers']\n",
    "\n",
    "#adding market share per store-period to the main data\n",
    "market_sizes=market_sizes[['state','period','per store market']]#extracting only relevant columns from market_sizes\n",
    "merge_cols=['state','period']\n",
    "summary_with_market_shares=pd.merge(sales_sum_df,market_sizes, on=merge_cols,how='inner')\n",
    "\n",
    "#computing So\n",
    "\n",
    "# summary_with_market_shares['so'] = summary_with_market_shares['per store type market']-summary_with_market_shares['sales_quantity']\n",
    "\n",
    "summary_with_market_shares['so']=summary_with_market_shares['per store market']-summary_with_market_shares['sales_quantity']\n",
    "summary_with_market_shares = summary_with_market_shares[summary_with_market_shares['so'] != 0]\n",
    "\n",
    "#computing log(S/So) [replacing zeros with 1e-08 so that logs dont create a problem]\n",
    "summary_with_market_shares['so']=summary_with_market_shares['sales_quantity'].replace(0,10**(-5)).div(summary_with_market_shares['so'],axis=0)\n",
    "summary_with_market_shares['so']=np.log(summary_with_market_shares['so'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(summary_with_market_shares[summary_with_market_shares['so'].isin([np.inf, -np.inf, np.nan])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary_with_market_shares = summary_with_market_shares[~(summary_with_market_shares['so'].isin([np.inf, -np.inf, np.nan]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_quantity</th>\n",
       "      <th>per store market</th>\n",
       "      <th>so</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sales_quantity, per store market, so]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for NaNs\n",
    "d=summary_with_market_shares[['sales_quantity','per store market','so']]\n",
    "d[d.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -19.807252\n",
       "1   -19.807252\n",
       "2   -19.807252\n",
       "3   -19.807252\n",
       "4    -8.294076\n",
       "Name: so, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_with_market_shares['so'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4001.10742\n",
       "1    4001.10742\n",
       "2    4001.10742\n",
       "3    4001.10742\n",
       "4    4001.10742\n",
       "Name: per store market, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_with_market_shares['per store market'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting specific columns\n",
    "\n",
    "col=[ 'item_no','period', 'state', 'region',\n",
    "       'brand', 'stock_prevailing_mrp', 'store_type', 'store_location', 'city_type',\n",
    "       'available_quantity',  'case_size_range',\n",
    "       'gender', 'movement', 'material', 'dial_color', 'strap_type',\n",
    "       'strap_color', 'precious_stone', 'glass', 'case_shape', 'watch_type','billing','sales_quantity','so']\n",
    "\n",
    "summary_final=summary_with_market_shares.loc[:,col]\n",
    "#df_north_final.fillna(0, inplace=True)\n",
    "\n",
    "summary_final['item_no']=summary_final['item_no'].astype(str)\n",
    "summary_final['period']=summary_final['period'].astype(str)\n",
    "summary_final['case_shape']=summary_final['case_shape'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#creating dummy variables\n",
    "cols=['brand','state','region', 'store_type', 'store_location', 'city_type',\n",
    "       'case_size_range', 'gender', 'movement', 'material', 'dial_color',\n",
    "       'strap_type', 'strap_color', 'precious_stone', 'glass', 'case_shape',\n",
    "       'watch_type', 'period']\n",
    "summary_final_dummies=pd.get_dummies(data=summary_final, columns=cols)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 374005 entries, 0 to 375663\n",
      "Columns: 378 entries, item_no to period_9\n",
      "dtypes: float64(5), object(1), uint8(372)\n",
      "memory usage: 152.7+ MB\n"
     ]
    }
   ],
   "source": [
    "summary_final_dummies.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for So as the target variable\n",
    "#creating seperate df for independent and dependent features\n",
    "y=summary_final_dummies.loc[:, summary_final_dummies.columns == 'sales_quantity']\n",
    "X=summary_final_dummies.drop(columns =['sales_quantity','item_no','billing', 'so'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374005, 378)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_final_dummies.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for duplicate column names\n",
    "duplicate_columns = summary_final_dummies.columns[summary_final_dummies.columns.duplicated()]\n",
    "duplicate_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsplit=0.2\\ntest=int(len(X)*split)\\ntrain=len(X)-test\\nX_train=X.head(train)\\ny_train=y.head(train)\\nX_test=X.tail(test)\\ny_test=y.tail(test)\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing train and test split on data\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "split=0.2\n",
    "test=int(len(X)*split)\n",
    "train=len(X)-test\n",
    "X_train=X.head(train)\n",
    "y_train=y.head(train)\n",
    "X_test=X.tail(test)\n",
    "y_test=y.tail(test)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = summary_final_dummies.loc[:, summary_final_dummies.columns == 'so']\n",
    "X_train2,X_test2, y_train2, y_test2 = train_test_split(X, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg_model = LinearRegression()  \n",
    "reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression RMSE: 1.26, Test R2: 0.77\n"
     ]
    }
   ],
   "source": [
    "r2=r2_score(y_test, preds)\n",
    "print(\"Linear regression RMSE: %.2f, Test R2: %.2f\" % (rmse,r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression on so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression RMSE: 5.24, Test R2: 0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg_model_so = LinearRegression()  \n",
    "reg_model_so.fit(X_train2, y_train2)\n",
    "preds_so = reg_model_so.predict(X_test2)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "rmse = np.sqrt(mean_squared_error(y_test2, preds_so))\n",
    "r2=r2_score(y_test2, preds_so)\n",
    "print(\"Linear regression RMSE: %.2f, Test R2: %.2f\" % (rmse,r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parulgaba/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/parulgaba/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bylevel=0.5, min_child_weight=7, colsample_bytree = 0.5, reg_alpha=0.7, reg_lambda=0.7, subsample=0.3, learning_rate = 0.15,max_depth = 10, alpha = 10, n_estimators = 5)\n",
    "xg_reg.fit(X_train,y_train)\n",
    "preds = xg_reg.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost RMSE: 2.56, Test R2: 0.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test,preds)\n",
    "print(\"Xgboost RMSE: %.2f, Test R2: %.2f\" % (rmse,r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] subsample=0.8, reg_lambda=0.2, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=4, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:29:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.8, reg_lambda=0.2, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=4, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.4, score=-0.676, total= 1.4min\n",
      "[CV] subsample=0.8, reg_lambda=0.2, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=4, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:30:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.8, reg_lambda=0.2, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=4, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.4, score=-2.527, total= 1.4min\n",
      "[CV] subsample=0.8, reg_lambda=0.2, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=4, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:31:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.8, reg_lambda=0.2, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=4, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.4, score=-0.664, total= 1.4min\n",
      "[CV] subsample=0.8, reg_lambda=0.2, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=4, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.4 \n",
      "[18:33:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.8, reg_lambda=0.2, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=4, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.4, score=-0.696, total= 1.4min\n",
      "[CV] subsample=0.8, reg_lambda=0.2, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=4, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.4 \n",
      "[18:34:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.8, reg_lambda=0.2, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=4, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.4, score=-1.915, total= 1.5min\n",
      "[CV] subsample=0.3, reg_lambda=0.5, reg_alpha=0.5, n_estimator=5, min_child_weight=7, max_depth=15, learning_rate=0.2, colsample_bytree=0.5, colsample_bylevel=0.6 \n",
      "[18:36:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.3, reg_lambda=0.5, reg_alpha=0.5, n_estimator=5, min_child_weight=7, max_depth=15, learning_rate=0.2, colsample_bytree=0.5, colsample_bylevel=0.6, score=-0.709, total= 2.7min\n",
      "[CV] subsample=0.3, reg_lambda=0.5, reg_alpha=0.5, n_estimator=5, min_child_weight=7, max_depth=15, learning_rate=0.2, colsample_bytree=0.5, colsample_bylevel=0.6 \n",
      "[18:38:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.3, reg_lambda=0.5, reg_alpha=0.5, n_estimator=5, min_child_weight=7, max_depth=15, learning_rate=0.2, colsample_bytree=0.5, colsample_bylevel=0.6, score=-2.415, total= 2.8min\n",
      "[CV] subsample=0.3, reg_lambda=0.5, reg_alpha=0.5, n_estimator=5, min_child_weight=7, max_depth=15, learning_rate=0.2, colsample_bytree=0.5, colsample_bylevel=0.6 \n",
      "[18:41:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.3, reg_lambda=0.5, reg_alpha=0.5, n_estimator=5, min_child_weight=7, max_depth=15, learning_rate=0.2, colsample_bytree=0.5, colsample_bylevel=0.6, score=-0.665, total= 3.0min\n",
      "[CV] subsample=0.3, reg_lambda=0.5, reg_alpha=0.5, n_estimator=5, min_child_weight=7, max_depth=15, learning_rate=0.2, colsample_bytree=0.5, colsample_bylevel=0.6 \n",
      "[18:44:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.3, reg_lambda=0.5, reg_alpha=0.5, n_estimator=5, min_child_weight=7, max_depth=15, learning_rate=0.2, colsample_bytree=0.5, colsample_bylevel=0.6, score=-0.639, total= 3.2min\n",
      "[CV] subsample=0.3, reg_lambda=0.5, reg_alpha=0.5, n_estimator=5, min_child_weight=7, max_depth=15, learning_rate=0.2, colsample_bytree=0.5, colsample_bylevel=0.6 \n",
      "[18:47:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.3, reg_lambda=0.5, reg_alpha=0.5, n_estimator=5, min_child_weight=7, max_depth=15, learning_rate=0.2, colsample_bytree=0.5, colsample_bylevel=0.6, score=-0.775, total= 3.4min\n",
      "[CV] subsample=0.9, reg_lambda=0.4, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.8 \n",
      "[18:51:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.9, reg_lambda=0.4, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.8, score=-0.843, total= 3.4min\n",
      "[CV] subsample=0.9, reg_lambda=0.4, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.8 \n",
      "[18:54:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.9, reg_lambda=0.4, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.8, score=-2.772, total= 3.5min\n",
      "[CV] subsample=0.9, reg_lambda=0.4, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.8 \n",
      "[18:58:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.9, reg_lambda=0.4, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.8, score=-0.637, total= 3.5min\n",
      "[CV] subsample=0.9, reg_lambda=0.4, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.8 \n",
      "[19:01:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.9, reg_lambda=0.4, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.8, score=-0.771, total= 3.2min\n",
      "[CV] subsample=0.9, reg_lambda=0.4, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.8 \n",
      "[19:04:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.9, reg_lambda=0.4, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.8, score=-2.793, total= 3.0min\n",
      "[CV] subsample=0.2, reg_lambda=0.5, reg_alpha=0.9, n_estimator=5, min_child_weight=5, max_depth=10, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.4 \n",
      "[19:07:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.5, reg_alpha=0.9, n_estimator=5, min_child_weight=5, max_depth=10, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.4, score=-0.587, total= 1.2min\n",
      "[CV] subsample=0.2, reg_lambda=0.5, reg_alpha=0.9, n_estimator=5, min_child_weight=5, max_depth=10, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.4 \n",
      "[19:09:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.5, reg_alpha=0.9, n_estimator=5, min_child_weight=5, max_depth=10, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.4, score=-2.568, total= 1.1min\n",
      "[CV] subsample=0.2, reg_lambda=0.5, reg_alpha=0.9, n_estimator=5, min_child_weight=5, max_depth=10, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.4 \n",
      "[19:10:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.5, reg_alpha=0.9, n_estimator=5, min_child_weight=5, max_depth=10, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.4, score=-0.647, total= 1.1min\n",
      "[CV] subsample=0.2, reg_lambda=0.5, reg_alpha=0.9, n_estimator=5, min_child_weight=5, max_depth=10, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.4 \n",
      "[19:11:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.5, reg_alpha=0.9, n_estimator=5, min_child_weight=5, max_depth=10, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.4, score=-0.639, total= 1.1min\n",
      "[CV] subsample=0.2, reg_lambda=0.5, reg_alpha=0.9, n_estimator=5, min_child_weight=5, max_depth=10, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.4 \n",
      "[19:12:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.5, reg_alpha=0.9, n_estimator=5, min_child_weight=5, max_depth=10, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.4, score=-0.613, total= 1.1min\n",
      "[CV] subsample=0.3, reg_lambda=0.2, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.7, colsample_bylevel=0.3 \n",
      "[19:13:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.3, reg_lambda=0.2, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.7, colsample_bylevel=0.3, score=-0.655, total= 1.0min\n",
      "[CV] subsample=0.3, reg_lambda=0.2, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.7, colsample_bylevel=0.3 \n",
      "[19:14:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.3, reg_lambda=0.2, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.7, colsample_bylevel=0.3, score=-2.532, total=  59.9s\n",
      "[CV] subsample=0.3, reg_lambda=0.2, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.7, colsample_bylevel=0.3 \n",
      "[19:15:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.3, reg_lambda=0.2, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.7, colsample_bylevel=0.3, score=-0.604, total= 1.0min\n",
      "[CV] subsample=0.3, reg_lambda=0.2, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.7, colsample_bylevel=0.3 \n",
      "[19:16:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.3, reg_lambda=0.2, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.7, colsample_bylevel=0.3, score=-0.945, total= 1.1min\n",
      "[CV] subsample=0.3, reg_lambda=0.2, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.7, colsample_bylevel=0.3 \n",
      "[19:17:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.3, reg_lambda=0.2, reg_alpha=0.3, n_estimator=3, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.7, colsample_bylevel=0.3, score=-1.562, total= 1.0min\n",
      "[CV] subsample=0.1, reg_lambda=0.5, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.1 \n",
      "[19:18:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.1, reg_lambda=0.5, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.1, score=-0.680, total=  33.4s\n",
      "[CV] subsample=0.1, reg_lambda=0.5, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.1 \n",
      "[19:19:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.1, reg_lambda=0.5, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.1, score=-2.480, total=  34.5s\n",
      "[CV] subsample=0.1, reg_lambda=0.5, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.1 \n",
      "[19:19:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.1, reg_lambda=0.5, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.1, score=-1.090, total=  45.9s\n",
      "[CV] subsample=0.1, reg_lambda=0.5, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.1 \n",
      "[19:20:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.1, reg_lambda=0.5, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.1, score=-0.882, total=  47.9s\n",
      "[CV] subsample=0.1, reg_lambda=0.5, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.1 \n",
      "[19:21:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.1, reg_lambda=0.5, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.5, colsample_bylevel=0.1, score=-1.091, total=  59.8s\n",
      "[CV] subsample=0.2, reg_lambda=0.2, reg_alpha=0.8, n_estimator=7, min_child_weight=5, max_depth=5, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.8 \n",
      "[19:22:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.2, reg_alpha=0.8, n_estimator=7, min_child_weight=5, max_depth=5, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.8, score=-0.621, total= 1.5min\n",
      "[CV] subsample=0.2, reg_lambda=0.2, reg_alpha=0.8, n_estimator=7, min_child_weight=5, max_depth=5, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.8 \n",
      "[19:23:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.2, reg_alpha=0.8, n_estimator=7, min_child_weight=5, max_depth=5, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.8, score=-2.538, total= 1.2min\n",
      "[CV] subsample=0.2, reg_lambda=0.2, reg_alpha=0.8, n_estimator=7, min_child_weight=5, max_depth=5, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.8 \n",
      "[19:24:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.2, reg_alpha=0.8, n_estimator=7, min_child_weight=5, max_depth=5, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.8, score=-0.641, total=  59.5s\n",
      "[CV] subsample=0.2, reg_lambda=0.2, reg_alpha=0.8, n_estimator=7, min_child_weight=5, max_depth=5, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.8 \n",
      "[19:25:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.2, reg_alpha=0.8, n_estimator=7, min_child_weight=5, max_depth=5, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.8, score=-0.652, total= 1.0min\n",
      "[CV] subsample=0.2, reg_lambda=0.2, reg_alpha=0.8, n_estimator=7, min_child_weight=5, max_depth=5, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.8 \n",
      "[19:26:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.2, reg_alpha=0.8, n_estimator=7, min_child_weight=5, max_depth=5, learning_rate=0.05, colsample_bytree=0.4, colsample_bylevel=0.8, score=-0.625, total= 1.0min\n",
      "[CV] subsample=0.6, reg_lambda=0.3, reg_alpha=0.5, n_estimator=5, min_child_weight=1, max_depth=15, learning_rate=0.2, colsample_bytree=0.3, colsample_bylevel=0.4 \n",
      "[19:28:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.3, reg_alpha=0.5, n_estimator=5, min_child_weight=1, max_depth=15, learning_rate=0.2, colsample_bytree=0.3, colsample_bylevel=0.4, score=-0.599, total= 1.9min\n",
      "[CV] subsample=0.6, reg_lambda=0.3, reg_alpha=0.5, n_estimator=5, min_child_weight=1, max_depth=15, learning_rate=0.2, colsample_bytree=0.3, colsample_bylevel=0.4 \n",
      "[19:29:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.3, reg_alpha=0.5, n_estimator=5, min_child_weight=1, max_depth=15, learning_rate=0.2, colsample_bytree=0.3, colsample_bylevel=0.4, score=-2.740, total= 2.2min\n",
      "[CV] subsample=0.6, reg_lambda=0.3, reg_alpha=0.5, n_estimator=5, min_child_weight=1, max_depth=15, learning_rate=0.2, colsample_bytree=0.3, colsample_bylevel=0.4 \n",
      "[19:32:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.3, reg_alpha=0.5, n_estimator=5, min_child_weight=1, max_depth=15, learning_rate=0.2, colsample_bytree=0.3, colsample_bylevel=0.4, score=-0.682, total= 3.3min\n",
      "[CV] subsample=0.6, reg_lambda=0.3, reg_alpha=0.5, n_estimator=5, min_child_weight=1, max_depth=15, learning_rate=0.2, colsample_bytree=0.3, colsample_bylevel=0.4 \n",
      "[19:35:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.3, reg_alpha=0.5, n_estimator=5, min_child_weight=1, max_depth=15, learning_rate=0.2, colsample_bytree=0.3, colsample_bylevel=0.4, score=-0.945, total= 3.5min\n",
      "[CV] subsample=0.6, reg_lambda=0.3, reg_alpha=0.5, n_estimator=5, min_child_weight=1, max_depth=15, learning_rate=0.2, colsample_bytree=0.3, colsample_bylevel=0.4 \n",
      "[19:38:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.3, reg_alpha=0.5, n_estimator=5, min_child_weight=1, max_depth=15, learning_rate=0.2, colsample_bytree=0.3, colsample_bylevel=0.4, score=-2.209, total= 3.2min\n",
      "[CV] subsample=0.2, reg_lambda=0.6, reg_alpha=0.4, n_estimator=10, min_child_weight=5, max_depth=4, learning_rate=0.05, colsample_bytree=0.8, colsample_bylevel=0.6 \n",
      "[19:42:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.6, reg_alpha=0.4, n_estimator=10, min_child_weight=5, max_depth=4, learning_rate=0.05, colsample_bytree=0.8, colsample_bylevel=0.6, score=-0.635, total= 2.1min\n",
      "[CV] subsample=0.2, reg_lambda=0.6, reg_alpha=0.4, n_estimator=10, min_child_weight=5, max_depth=4, learning_rate=0.05, colsample_bytree=0.8, colsample_bylevel=0.6 \n",
      "[19:44:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.6, reg_alpha=0.4, n_estimator=10, min_child_weight=5, max_depth=4, learning_rate=0.05, colsample_bytree=0.8, colsample_bylevel=0.6, score=-2.487, total= 1.7min\n",
      "[CV] subsample=0.2, reg_lambda=0.6, reg_alpha=0.4, n_estimator=10, min_child_weight=5, max_depth=4, learning_rate=0.05, colsample_bytree=0.8, colsample_bylevel=0.6 \n",
      "[19:45:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.6, reg_alpha=0.4, n_estimator=10, min_child_weight=5, max_depth=4, learning_rate=0.05, colsample_bytree=0.8, colsample_bylevel=0.6, score=-0.630, total= 1.5min\n",
      "[CV] subsample=0.2, reg_lambda=0.6, reg_alpha=0.4, n_estimator=10, min_child_weight=5, max_depth=4, learning_rate=0.05, colsample_bytree=0.8, colsample_bylevel=0.6 \n",
      "[19:47:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.6, reg_alpha=0.4, n_estimator=10, min_child_weight=5, max_depth=4, learning_rate=0.05, colsample_bytree=0.8, colsample_bylevel=0.6, score=-0.649, total= 1.6min\n",
      "[CV] subsample=0.2, reg_lambda=0.6, reg_alpha=0.4, n_estimator=10, min_child_weight=5, max_depth=4, learning_rate=0.05, colsample_bytree=0.8, colsample_bylevel=0.6 \n",
      "[19:49:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.6, reg_alpha=0.4, n_estimator=10, min_child_weight=5, max_depth=4, learning_rate=0.05, colsample_bytree=0.8, colsample_bylevel=0.6, score=-0.630, total= 1.6min\n",
      "[CV] subsample=0.4, reg_lambda=0.9, reg_alpha=0.6, n_estimator=10, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.2 \n",
      "[19:50:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.4, reg_lambda=0.9, reg_alpha=0.6, n_estimator=10, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.2, score=-0.649, total= 1.7min\n",
      "[CV] subsample=0.4, reg_lambda=0.9, reg_alpha=0.6, n_estimator=10, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.2 \n",
      "[19:52:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.4, reg_lambda=0.9, reg_alpha=0.6, n_estimator=10, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.2, score=-2.805, total= 1.9min\n",
      "[CV] subsample=0.4, reg_lambda=0.9, reg_alpha=0.6, n_estimator=10, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.2 \n",
      "[19:54:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.4, reg_lambda=0.9, reg_alpha=0.6, n_estimator=10, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.2, score=-0.600, total= 1.9min\n",
      "[CV] subsample=0.4, reg_lambda=0.9, reg_alpha=0.6, n_estimator=10, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.2 \n",
      "[19:56:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.4, reg_lambda=0.9, reg_alpha=0.6, n_estimator=10, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.2, score=-0.622, total= 2.2min\n",
      "[CV] subsample=0.4, reg_lambda=0.9, reg_alpha=0.6, n_estimator=10, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.2 \n",
      "[19:58:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.4, reg_lambda=0.9, reg_alpha=0.6, n_estimator=10, min_child_weight=1, max_depth=8, learning_rate=0.25, colsample_bytree=0.9, colsample_bylevel=0.2, score=-2.248, total= 1.6min\n",
      "[CV] subsample=0.6, reg_lambda=0.3, reg_alpha=0.7, n_estimator=10, min_child_weight=7, max_depth=12, learning_rate=0.2, colsample_bytree=0.2, colsample_bylevel=0.9 \n",
      "[19:59:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.3, reg_alpha=0.7, n_estimator=10, min_child_weight=7, max_depth=12, learning_rate=0.2, colsample_bytree=0.2, colsample_bylevel=0.9, score=-0.637, total= 3.2min\n",
      "[CV] subsample=0.6, reg_lambda=0.3, reg_alpha=0.7, n_estimator=10, min_child_weight=7, max_depth=12, learning_rate=0.2, colsample_bytree=0.2, colsample_bylevel=0.9 \n",
      "[20:03:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.3, reg_alpha=0.7, n_estimator=10, min_child_weight=7, max_depth=12, learning_rate=0.2, colsample_bytree=0.2, colsample_bylevel=0.9, score=-2.318, total= 3.0min\n",
      "[CV] subsample=0.6, reg_lambda=0.3, reg_alpha=0.7, n_estimator=10, min_child_weight=7, max_depth=12, learning_rate=0.2, colsample_bytree=0.2, colsample_bylevel=0.9 \n",
      "[20:06:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.3, reg_alpha=0.7, n_estimator=10, min_child_weight=7, max_depth=12, learning_rate=0.2, colsample_bytree=0.2, colsample_bylevel=0.9, score=-0.585, total= 2.9min\n",
      "[CV] subsample=0.6, reg_lambda=0.3, reg_alpha=0.7, n_estimator=10, min_child_weight=7, max_depth=12, learning_rate=0.2, colsample_bytree=0.2, colsample_bylevel=0.9 \n",
      "[20:09:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.3, reg_alpha=0.7, n_estimator=10, min_child_weight=7, max_depth=12, learning_rate=0.2, colsample_bytree=0.2, colsample_bylevel=0.9, score=-0.615, total= 3.5min\n",
      "[CV] subsample=0.6, reg_lambda=0.3, reg_alpha=0.7, n_estimator=10, min_child_weight=7, max_depth=12, learning_rate=0.2, colsample_bytree=0.2, colsample_bylevel=0.9 \n",
      "[20:12:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.3, reg_alpha=0.7, n_estimator=10, min_child_weight=7, max_depth=12, learning_rate=0.2, colsample_bytree=0.2, colsample_bylevel=0.9, score=-0.783, total= 3.7min\n",
      "[CV] subsample=0.6, reg_lambda=0.2, reg_alpha=0.8, n_estimator=3, min_child_weight=7, max_depth=5, learning_rate=0.2, colsample_bytree=0.6, colsample_bylevel=0.1 \n",
      "[20:16:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.2, reg_alpha=0.8, n_estimator=3, min_child_weight=7, max_depth=5, learning_rate=0.2, colsample_bytree=0.6, colsample_bylevel=0.1, score=-0.651, total= 1.2min\n",
      "[CV] subsample=0.6, reg_lambda=0.2, reg_alpha=0.8, n_estimator=3, min_child_weight=7, max_depth=5, learning_rate=0.2, colsample_bytree=0.6, colsample_bylevel=0.1 \n",
      "[20:17:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.2, reg_alpha=0.8, n_estimator=3, min_child_weight=7, max_depth=5, learning_rate=0.2, colsample_bytree=0.6, colsample_bylevel=0.1, score=-2.350, total= 1.1min\n",
      "[CV] subsample=0.6, reg_lambda=0.2, reg_alpha=0.8, n_estimator=3, min_child_weight=7, max_depth=5, learning_rate=0.2, colsample_bytree=0.6, colsample_bylevel=0.1 \n",
      "[20:18:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.2, reg_alpha=0.8, n_estimator=3, min_child_weight=7, max_depth=5, learning_rate=0.2, colsample_bytree=0.6, colsample_bylevel=0.1, score=-0.546, total= 1.1min\n",
      "[CV] subsample=0.6, reg_lambda=0.2, reg_alpha=0.8, n_estimator=3, min_child_weight=7, max_depth=5, learning_rate=0.2, colsample_bytree=0.6, colsample_bylevel=0.1 \n",
      "[20:19:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.2, reg_alpha=0.8, n_estimator=3, min_child_weight=7, max_depth=5, learning_rate=0.2, colsample_bytree=0.6, colsample_bylevel=0.1, score=-0.642, total= 1.3min\n",
      "[CV] subsample=0.6, reg_lambda=0.2, reg_alpha=0.8, n_estimator=3, min_child_weight=7, max_depth=5, learning_rate=0.2, colsample_bytree=0.6, colsample_bylevel=0.1 \n",
      "[20:21:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.6, reg_lambda=0.2, reg_alpha=0.8, n_estimator=3, min_child_weight=7, max_depth=5, learning_rate=0.2, colsample_bytree=0.6, colsample_bylevel=0.1, score=-0.860, total= 1.1min\n",
      "[CV] subsample=0.1, reg_lambda=0.6, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=6, learning_rate=0.15, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[20:22:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.1, reg_lambda=0.6, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=6, learning_rate=0.15, colsample_bytree=0.6, colsample_bylevel=0.8, score=-0.632, total= 2.4min\n",
      "[CV] subsample=0.1, reg_lambda=0.6, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=6, learning_rate=0.15, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[20:24:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.1, reg_lambda=0.6, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=6, learning_rate=0.15, colsample_bytree=0.6, colsample_bylevel=0.8, score=-2.609, total= 3.1min\n",
      "[CV] subsample=0.1, reg_lambda=0.6, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=6, learning_rate=0.15, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[20:27:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.1, reg_lambda=0.6, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=6, learning_rate=0.15, colsample_bytree=0.6, colsample_bylevel=0.8, score=-0.718, total= 2.9min\n",
      "[CV] subsample=0.1, reg_lambda=0.6, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=6, learning_rate=0.15, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[20:30:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.1, reg_lambda=0.6, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=6, learning_rate=0.15, colsample_bytree=0.6, colsample_bylevel=0.8, score=-0.710, total= 3.3min\n",
      "[CV] subsample=0.1, reg_lambda=0.6, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=6, learning_rate=0.15, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[20:34:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.1, reg_lambda=0.6, reg_alpha=0.4, n_estimator=5, min_child_weight=5, max_depth=6, learning_rate=0.15, colsample_bytree=0.6, colsample_bylevel=0.8, score=-0.649, total= 3.6min\n",
      "[CV] subsample=0.8, reg_lambda=0.4, reg_alpha=0.8, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.2, colsample_bytree=0.1, colsample_bylevel=0.2 \n",
      "[20:37:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.8, reg_lambda=0.4, reg_alpha=0.8, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.2, colsample_bytree=0.1, colsample_bylevel=0.2, score=-0.722, total= 1.2min\n",
      "[CV] subsample=0.8, reg_lambda=0.4, reg_alpha=0.8, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.2, colsample_bytree=0.1, colsample_bylevel=0.2 \n",
      "[20:38:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.8, reg_lambda=0.4, reg_alpha=0.8, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.2, colsample_bytree=0.1, colsample_bylevel=0.2, score=-2.566, total= 1.3min\n",
      "[CV] subsample=0.8, reg_lambda=0.4, reg_alpha=0.8, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.2, colsample_bytree=0.1, colsample_bylevel=0.2 \n",
      "[20:40:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.8, reg_lambda=0.4, reg_alpha=0.8, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.2, colsample_bytree=0.1, colsample_bylevel=0.2, score=-0.699, total= 1.4min\n",
      "[CV] subsample=0.8, reg_lambda=0.4, reg_alpha=0.8, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.2, colsample_bytree=0.1, colsample_bylevel=0.2 \n",
      "[20:41:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.8, reg_lambda=0.4, reg_alpha=0.8, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.2, colsample_bytree=0.1, colsample_bylevel=0.2, score=-0.868, total= 1.4min\n",
      "[CV] subsample=0.8, reg_lambda=0.4, reg_alpha=0.8, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.2, colsample_bytree=0.1, colsample_bylevel=0.2 \n",
      "[20:42:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.8, reg_lambda=0.4, reg_alpha=0.8, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.2, colsample_bytree=0.1, colsample_bylevel=0.2, score=-1.304, total= 1.3min\n",
      "[CV] subsample=0.2, reg_lambda=0.2, reg_alpha=0.1, n_estimator=7, min_child_weight=3, max_depth=6, learning_rate=0.25, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[20:44:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.2, reg_alpha=0.1, n_estimator=7, min_child_weight=3, max_depth=6, learning_rate=0.25, colsample_bytree=0.6, colsample_bylevel=0.8, score=-0.883, total= 3.7min\n",
      "[CV] subsample=0.2, reg_lambda=0.2, reg_alpha=0.1, n_estimator=7, min_child_weight=3, max_depth=6, learning_rate=0.25, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[20:47:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.2, reg_alpha=0.1, n_estimator=7, min_child_weight=3, max_depth=6, learning_rate=0.25, colsample_bytree=0.6, colsample_bylevel=0.8, score=-2.532, total= 3.2min\n",
      "[CV] subsample=0.2, reg_lambda=0.2, reg_alpha=0.1, n_estimator=7, min_child_weight=3, max_depth=6, learning_rate=0.25, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[20:50:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.2, reg_alpha=0.1, n_estimator=7, min_child_weight=3, max_depth=6, learning_rate=0.25, colsample_bytree=0.6, colsample_bylevel=0.8, score=-0.817, total= 3.2min\n",
      "[CV] subsample=0.2, reg_lambda=0.2, reg_alpha=0.1, n_estimator=7, min_child_weight=3, max_depth=6, learning_rate=0.25, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[20:54:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.2, reg_alpha=0.1, n_estimator=7, min_child_weight=3, max_depth=6, learning_rate=0.25, colsample_bytree=0.6, colsample_bylevel=0.8, score=-0.993, total= 3.2min\n",
      "[CV] subsample=0.2, reg_lambda=0.2, reg_alpha=0.1, n_estimator=7, min_child_weight=3, max_depth=6, learning_rate=0.25, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[20:57:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.2, reg_lambda=0.2, reg_alpha=0.1, n_estimator=7, min_child_weight=3, max_depth=6, learning_rate=0.25, colsample_bytree=0.6, colsample_bylevel=0.8, score=-1.193, total= 3.0min\n",
      "[CV] subsample=0.5, reg_lambda=0.4, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.2, colsample_bylevel=0.7 \n",
      "[21:00:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.5, reg_lambda=0.4, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.2, colsample_bylevel=0.7, score=-0.648, total= 2.0min\n",
      "[CV] subsample=0.5, reg_lambda=0.4, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.2, colsample_bylevel=0.7 \n",
      "[21:02:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.5, reg_lambda=0.4, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.2, colsample_bylevel=0.7, score=-2.662, total= 2.0min\n",
      "[CV] subsample=0.5, reg_lambda=0.4, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.2, colsample_bylevel=0.7 \n",
      "[21:04:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.5, reg_lambda=0.4, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.2, colsample_bylevel=0.7, score=-0.668, total= 2.4min\n",
      "[CV] subsample=0.5, reg_lambda=0.4, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.2, colsample_bylevel=0.7 \n",
      "[21:06:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV]  subsample=0.5, reg_lambda=0.4, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.2, colsample_bylevel=0.7, score=-0.890, total= 2.4min\n",
      "[CV] subsample=0.5, reg_lambda=0.4, reg_alpha=0.3, n_estimator=7, min_child_weight=1, max_depth=6, learning_rate=0.1, colsample_bytree=0.2, colsample_bylevel=0.7 \n",
      "[21:09:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-ad080a49c836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxg_reg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1529\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1368\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'colsample_bytree': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "          'subsample': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "          'colsample_bylevel':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "          'min_child_weight':[1,3,5,7] ,\n",
    "          'reg_lambda':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "          'n_estimator':[3,5,7,10],\n",
    "          'learning_rate': [0.05,0.1,0.15,0.2,0.25,0.3],\n",
    "          'max_depth': [3,4,5,6,7,8,10,12,15], \n",
    "          'reg_alpha': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "         }\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "#scoring='r2'\n",
    "scoring='neg_mean_squared_error'\n",
    "random_search=RandomizedSearchCV(xg_reg,param_distributions=params,scoring=scoring,n_iter=20,cv=5,verbose=3)\n",
    "\n",
    "random_search.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model based on the output of random_search.best_estimator_\n",
    "best_gb=xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
    "             colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.1, max_delta_step=0, max_depth=12,\n",
    "             min_child_weight =7, missing=np.nan,\n",
    "              n_estimator=3, n_estimators=100,\n",
    "             n_jobs=0, num_parallel_tree=1, objective='reg:squarederror',\n",
    "             random_state=0, reg_alpha=0.5, reg_lambda=0.3, scale_pos_weight=1,\n",
    "             subsample=0.2, tree_method='exact', validate_parameters=1,\n",
    "             verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score as cvs\n",
    "score=cvs(best_gb,X_train,y_train,cv=2,scoring='r2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gb.fit(X_train,y_train)\n",
    "preds = best_gb.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "r2=r2_score(y_test,preds)\n",
    "print(\"RMSE: %.2f, R2: %.2f\" % (rmse,r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
